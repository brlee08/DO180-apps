{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Question Answering with Generative Models on Vertex AI\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/examples/prompt-design/question_answering.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/prompt-design/question_answering.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/prompt-design/question_answering.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Large language models can be used for various natural language processing tasks, including question-answering (Q&A). These models are trained on a vast amount text data and can generate high-quality responses to a wide range of questions. One thing to note here is that most models have cutoff dates regarding their knowledge, and asking anything too recent might yield an incomplete, imaginative or incorrect answer (i.e. a hallucination).\n",
        "\n",
        "This notebook covers the essentials of prompts for answering questions using a generative model. In addition, it showcases the `open domain` (knowledge available on the public internet) and `closed domain` (knowledge that is more private - typically enterprise or personal knowledge).\n",
        "\n",
        "Learn more about prompt design in the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview#prompt_structure)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "By the end of the notebook, you should be able to write prompts for the following:\n",
        "\n",
        "* **Open domain** questions:\n",
        "    * Zero-shot prompting\n",
        "    * Few-shot prompting\n",
        "\n",
        "\n",
        "* **Closed domain** questions:\n",
        "    * Providing custom knowledge as context\n",
        "    * Instruction-tune the outputs\n",
        "    * Few-shot prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDU0XJ1xRDlL"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a5AEr0lkLKD"
      },
      "source": [
        "### Install Vertex AI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "82ad0c445061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "bf5aa79c-2243-411b-f702-2e5a96256967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.29.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.10.0)\n",
            "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_resource_manager-1.10.3-py2.py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.0/321.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely<2.0.0 (from google-cloud-aiplatform)\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.59.1)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.56.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.0)\n",
            "Installing collected packages: shapely, google-cloud-resource-manager, google-cloud-aiplatform\n",
            "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.29.0 google-cloud-resource-manager-1.10.3 shapely-1.8.5.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQR4etYzACLC"
      },
      "source": [
        "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Hsqwn4hkLKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfaa9d3-228e-493d-f21a-8b387dac32a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe7OuYuGkLKF"
      },
      "source": [
        "### Authenticating your notebook environment\n",
        "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
        "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U9Gx2SAZkLKF"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQdhUarHACLD"
      },
      "source": [
        "**Colab only:** Uncomment the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mHHXtn5dACLD"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"instantml-workshop-brlee\"  # @param {type:\"string\"}\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from vertexai.language_models import TextGenerationModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP76a2la7O-a"
      },
      "source": [
        "### Import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7isig7e07O-a"
      },
      "outputs": [],
      "source": [
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIPcn5dZ7O-b"
      },
      "source": [
        "## Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNNEz7vGFYUP"
      },
      "source": [
        "Question-answering capabilities require providing a prompt or a question that the model can use to generate a response. The prompt can be a few words or a few complete sentences, depending on the complexity of the question.\n",
        "\n",
        "When creating a question-answering prompt, it is essential to be specific and provide as much context as possible. It helps the model understand the intent behind the question and generate a relevant response. For example, if you want to ask:\n",
        "\n",
        "```\n",
        "\"What is the capital of France?\",\n",
        "\n",
        "then a good prompt could be:\n",
        "\n",
        "\"Please tell me the name of the city that serves as the capital of France.\"\n",
        "\n",
        "```\n",
        "\n",
        "In addition to being specific, the prompt should also be grammatically correct and free of spelling errors. It helps the model generate a response that is easy to understand and contains fewer errors or inaccuracies.\n",
        "\n",
        "By providing specific, context-rich prompts, you can help the model understand the intent behind the question and generate accurate and relevant responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5N9ZnlECm-z"
      },
      "source": [
        "Below are some differences between the **open domain** and **closed domain** categories for question-answering prompts.\n",
        "\n",
        "* **Open domain**: All questions whose answers are available online already. They can belong to any category, like history, geography, countries, politics, chemistry, etc. These include trivia or general knowledge questions, like:\n",
        "\n",
        "```\n",
        "Q: Who won the Olympic gold in swimming?\n",
        "Q: Who is the President of [given country]?\n",
        "Q: Who wrote [specific book]\"?\n",
        "```\n",
        "\n",
        "Keep in mind the training cutoff of generative models, as questions involving information more recent than what the model was trained on might give incorrect or imaginative answers.\n",
        "\n",
        "\n",
        "* **Closed domain**: If you have some internal knowledge base not available on the public internet, then those belong to the _closed domain_ category.\n",
        "You can pass that \"private\" knowledge as context to the model. If prompted correctly, the model is more likely to answer from within the context provided and less likely to give answers beyond that from the open internet.\n",
        "\n",
        "Consider the example of building a Q&A bot over your internal product documentation. In this case, you can pass the complete documentation to the model and prompt it only to answer based on that.\n",
        "\n",
        "Typical prompt for **closed domain**:\n",
        "\n",
        "```\n",
        "Prompt: f\"\"\" Answer from the below context: \\n\\n\n",
        "\t\t   context: {your knowledge base} \\n\n",
        "\t\t   question: {question specific to that knowledge base}  \\n\n",
        "\t\t   answer: {to be predicted by model} \\n\n",
        "\t\t\"\"\"\n",
        "```\n",
        "\n",
        "Below are some examples to understand these different types of prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBoN6zixDSiX"
      },
      "source": [
        "### Open Domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJnv8XhnDXQm"
      },
      "source": [
        "#### Zero-shot prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PaYoQuRwCm-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdef6973-b889-4b60-947f-f1950f0b9743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dwight D. Eisenhower, Republican\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Q: Who was President of the United States in 1955? Which party did he belong to?\\n\n",
        "            A:\n",
        "         \"\"\"\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "        max_output_tokens=256,\n",
        "        temperature=0.1,\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4qcUdUgwCm-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda0b610-21b9-4a0f-a3de-4f92517f5651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mount Everest\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Q: What is the tallest mountain in the world?\\n\n",
        "            A:\n",
        "         \"\"\"\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "        max_output_tokens=20,\n",
        "        temperature=0.1,\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HShw52X2Dcmx"
      },
      "source": [
        "#### Few-shot prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj_2hHAWE8vh"
      },
      "source": [
        "Let's say you want to a get a short answer from the model (like only a specific name). To do so, you can leverage a few-shot prompt and provide examples to the model to illustrate the expected behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RE5yCAaqDg7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae0f900-57aa-4131-f13f-c3fd6f4988d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexander Fleming\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Q: Who is the current President of France?\\n\n",
        "            A: Emmanuel Macron \\n\\n\n",
        "\n",
        "            Q: Who invented the telephone? \\n\n",
        "            A: Alexander Graham Bell \\n\\n\n",
        "\n",
        "            Q: Who wrote the novel \"1984\"?\n",
        "            A: George Orwell\n",
        "\n",
        "            Q: Who discovered penicillin?\n",
        "            A:\n",
        "         \"\"\"\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "        max_output_tokens=20,\n",
        "        temperature=0.1,\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGvs0jFsUlvM"
      },
      "source": [
        "#### Zero-shot prompting vs Few-shot prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yjsAMuMUfZC"
      },
      "source": [
        "Zero-shot prompting can be useful for quickly generating text for new tasks, but the quality of the generated text may be lower than that of a few-shot prompt with well-chosen examples. Few-shot prompting is typically better suited for tasks that require a high degree of specificity or domain-specific knowledge, but requires some additional thought and potentially data to set up the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6UiJTxXEs4t"
      },
      "source": [
        "### Closed Domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ZITm4AGBvP"
      },
      "source": [
        "#### Adding internal knowledge as context in prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkhqjmB6VqPx"
      },
      "source": [
        "Imagine a scenario where you would like to build a question-answering bot that takes in internal documentation and lets users ask questions about it.\n",
        "\n",
        "In the example below, the Google Cloud Storage and content policy documentation is added to the prompt, so that the PaLM API can use that to answer subsequent questions with the provided context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s1H2er_lExpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3f96a4-6183-40c5-941b-e05d4d734ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prompt]\n",
            "Answer the question given in the contex below:\n",
            "Context: \n",
            "Storage and content policy \n",
            "\n",
            "How durable is my data in Cloud Storage? \n",
            "\n",
            "Cloud Storage is designed for 99.999999999% (11 9's) annual durability, which is appropriate for even primary storage and\n",
            "business-critical applications. This high durability level is achieved through erasure coding that stores data pieces redundantly\n",
            "across multiple devices located in multiple availability zones.\n",
            "Objects written to Cloud Storage must be redundantly stored in at least two different availability zones before the\n",
            "write is acknowledged as successful. Checksums are stored and regularly revalidated to proactively verify that the data\n",
            "integrity of all data at rest as well as to detect corruption of data in transit. If required, corrections are automatically\n",
            "made using redundant data. Customers can optionally enable object versioning to add protection against accidental deletion.\n",
            "?\n",
            "\n",
            "Question: How is high availability achieved? \n",
            "\n",
            "Answer:\n",
            "\n",
            "[Response]\n",
            "The high availability of Cloud Storage is achieved through erasure coding that stores data pieces redundantly across multiple devices located in multiple availability zones.\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\"\n",
        "Storage and content policy \\n\n",
        "How durable is my data in Cloud Storage? \\n\n",
        "Cloud Storage is designed for 99.999999999% (11 9's) annual durability, which is appropriate for even primary storage and\n",
        "business-critical applications. This high durability level is achieved through erasure coding that stores data pieces redundantly\n",
        "across multiple devices located in multiple availability zones.\n",
        "Objects written to Cloud Storage must be redundantly stored in at least two different availability zones before the\n",
        "write is acknowledged as successful. Checksums are stored and regularly revalidated to proactively verify that the data\n",
        "integrity of all data at rest as well as to detect corruption of data in transit. If required, corrections are automatically\n",
        "made using redundant data. Customers can optionally enable object versioning to add protection against accidental deletion.\n",
        "\"\"\"\n",
        "\n",
        "question = \"How is high availability achieved?\"\n",
        "\n",
        "prompt = f\"\"\"Answer the question given in the contex below:\n",
        "Context: {context}?\\n\n",
        "Question: {question} \\n\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "print(\"[Prompt]\")\n",
        "print(prompt)\n",
        "\n",
        "print(\"[Response]\")\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tagWC4VcQIw6"
      },
      "source": [
        "#### Instruction-tuning outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9UkogWHXM6N"
      },
      "source": [
        "Another way to help out language models is to provide additional instructions to frame the output in the prompt. To ensure the model doesn't respond to anything outside the context, the prompt can specify that the response should be \"Information not available in provided context\" if that's the case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ouq8FfwSQIBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a615e8-88aa-4f93-8159-45ff7611b25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prompt]\n",
            "Answer the question given the context below as {Context:}. \n",
            "\n",
            "If the answer is not available in the {Context:} and you are not confident about the output,\n",
            "please say \"Information not available in provided context\". \n",
            "\n",
            "\n",
            "Context: \n",
            "Storage and content policy \n",
            "\n",
            "How durable is my data in Cloud Storage? \n",
            "\n",
            "Cloud Storage is designed for 99.999999999% (11 9's) annual durability, which is appropriate for even primary storage and\n",
            "business-critical applications. This high durability level is achieved through erasure coding that stores data pieces redundantly\n",
            "across multiple devices located in multiple availability zones.\n",
            "Objects written to Cloud Storage must be redundantly stored in at least two different availability zones before the\n",
            "write is acknowledged as successful. Checksums are stored and regularly revalidated to proactively verify that the data\n",
            "integrity of all data at rest as well as to detect corruption of data in transit. If required, corrections are automatically\n",
            "made using redundant data. Customers can optionally enable object versioning to add protection against accidental deletion.\n",
            "?\n",
            "\n",
            "Question: What machined are required for hosting Vertex AI models? \n",
            "\n",
            "Answer:\n",
            "\n",
            "[Response]\n",
            "Information not available in provided context\n"
          ]
        }
      ],
      "source": [
        "question = \"What machined are required for hosting Vertex AI models?\"\n",
        "prompt = f\"\"\"Answer the question given the context below as {{Context:}}. \\n\n",
        "If the answer is not available in the {{Context:}} and you are not confident about the output,\n",
        "please say \"Information not available in provided context\". \\n\\n\n",
        "Context: {context}?\\n\n",
        "Question: {question} \\n\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "print(\"[Prompt]\")\n",
        "print(prompt)\n",
        "\n",
        "print(\"[Response]\")\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "        max_output_tokens=256,\n",
        "        temperature=0.3,\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZJfZShPRGqU"
      },
      "source": [
        "#### Few-shot prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qdSEQeQIS6pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ee5ff9-25c2-43e6-9fe0-4dc9d7c4d353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leonardo da Vinci painted the Mona Lisa during the Italian Renaissance.\n"
          ]
        }
      ],
      "source": [
        "# Original 예제\n",
        "prompt = \"\"\"\n",
        "Context:\n",
        "The term \"artificial intelligence\" was first coined by John McCarthy in 1956. Since then, AI has developed into a vast\n",
        "field with numerous applications, ranging from self-driving cars to virtual assistants like Siri and Alexa.\n",
        "\n",
        "Question:\n",
        "What is artificial intelligence?\n",
        "\n",
        "Answer:\n",
        "Artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think and learn like humans.\n",
        "\n",
        "---\n",
        "\n",
        "Context:\n",
        "The Wright brothers, Orville and Wilbur, were two American aviation pioneers who are credited with inventing and\n",
        "building the world's first successful airplane and making the first controlled, powered and sustained heavier-than-air human flight,\n",
        " on December 17, 1903.\n",
        "\n",
        "Question:\n",
        "Who were the Wright brothers?\n",
        "\n",
        "Answer:\n",
        "The Wright brothers were American aviation pioneers who invented and built the world's first successful airplane\n",
        "and made the first controlled, powered and sustained heavier-than-air human flight, on December 17, 1903.\n",
        "\n",
        "---\n",
        "\n",
        "Context:\n",
        "The Mona Lisa is a 16th-century portrait painted by Leonardo da Vinci during the Italian Renaissance. It is one of\n",
        "the most famous paintings in the world, known for the enigmatic smile of the woman depicted in the painting.\n",
        "\n",
        "Question:\n",
        "Who painted the Mona Lisa?\n",
        "\n",
        "Answer:\n",
        "\n",
        "\"\"\"\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 고객 예제 테스트 1. 카카오 예제 (주로 규정집 기반 답변) - 규정집의 각 카테고리 별 내용을 Context 에 넣기 (each shot 마다 규정집 항목으로 context 정의)\n",
        "prompt = \"\"\"\n",
        "Context:\n",
        "1. 채용 및 근로계약\\n\n",
        "1-1. 채용 \\n\n",
        "① 입사지원자는 이력서 1통, 자기소개서 1통을 제출해야 합니다.\\n\n",
        "② 회사는 입사지원자에게 신체적 조건(용모‧키‧체중 등), 출신지역‧혼인여부‧재산, 직계존비속 및 형제자매의 학력‧직업‧재산 등 직무수행에 필요하지 않은 사항은 채용심사 등 의 자료로 요구하지 않습니다. \\n\n",
        "1-2. 근로계약 \\n\n",
        "① 회사는 근로계약 체결시 다음 내용을 해당자에게 명확히 제시하고, 1~6번 내용이 포함된 근로계약서 1부를 근로계약을 체결한 사원에게 줍니다. *해당 사원의 동의 하에 이를 전자적 방법(이메일 등)으로 보낼 수 있습니다. \\n\n",
        "1. 임금의 구성항목, 계산방법, 지급방법 2. 소정근로시간, 휴게시간 3. 휴일 4. 연차유급휴가 5. 취업의 장소 및 종사해야 할 업무에 관한 사항 6. 근로계약기간(기간제사원에 한정) 7. 근로기준법 제93조제1호부터 제12호까지에 해당하는 내용 8. 근로기준법 제10장에 따른 기숙사에 관한 사항(기숙사가 있는 경우에 한정) \\n\n",
        "② 회사는 근로계약 체결 시 제1항의 일부 내용을 대신하기 위한 것임을 명확히 밝히며 해당 내용이 적시된 취업규칙을 제시·교부할 수 있습니다. \\n\n",
        "1-3. 수습기간 \\n\n",
        "① 신규채용자는 최초로 근무를 개시한 날부터 ㅇ개월간을 수습기간으로 합니다. \\n\n",
        "② 제1항의 수습기간은 근속년수에 포함하되, 수습시작일부터 3개월 이내의 기간은 평균임금산정기간에는 포함하지 않습니다. \\n\n",
        "\n",
        "Question:\n",
        "근로계약\n",
        "\n",
        "Answer:\n",
        "① 회사는 근로계약 체결시 다음 내용을 해당자에게 명확히 제시하고, 1~6번 내용이 포함된 근로계약서 1부를 근로계약을 체결한 사원에게 줍니다. *해당 사원의 동의 하에 이를 전자적 방법(이메일 등)으로 보낼 수 있습니다. \\n\n",
        "1. 임금의 구성항목, 계산방법, 지급방법 2. 소정근로시간, 휴게시간 3. 휴일 4. 연차유급휴가 5. 취업의 장소 및 종사해야 할 업무에 관한 사항 6. 근로계약기간(기간제사원에 한정) 7. 근로기준법 제93조제1호부터 제12호까지에 해당하는 내용 8. 근로기준법 제10장에 따른 기숙사에 관한 사항(기숙사가 있는 경우에 한정) \\n\n",
        "② 회사는 근로계약 체결 시 제1항의 일부 내용을 대신하기 위한 것임을 명확히 밝히며 해당 내용이 적시된 취업규칙을 제시·교부할 수 있습니다. \\n\n",
        "\n",
        "Question:\n",
        "채용 시 제출 서류\n",
        "\n",
        "Answer:\n",
        "입사지원자는 이력서 1통, 자기소개서 1통을 제출해야 합니다.\\n\n",
        "\n",
        "---\n",
        "\n",
        "Context:\n",
        "2. 복무 \\n\n",
        "2-1. 복무의무 \\n\n",
        "1. 사원은 맡은바 직무를 충실히 수행해야 합니다. 2. 사원은 직무상 알게 된 비밀을 엄수하고 회사기밀을 누설해서는 안됩니다. 다만, 공익신고자 보호법상의 ‘공익신고자’의 경우에는 적용되지 않습니다. 3. 사원은 회사의 규정을 준수하고 상사의 정당한 직무상 지시에 따라야 합니다. 4. 사원은 사원으로서 품위를 손상하거나 회사의 명예를 실추시키는 행위를 해서는 안됩니다. \\n\n",
        "2-2. 출근, 결근 \\n\n",
        "① 사원은 업무시간 시작 전까지 출근해 업무에 임할 준비를 해 정상적인 업무수행에 차질이 없도록 해야 합니다. \\n\n",
        "② 질병이나 그 밖의 부득이한 사유로 결근하고자 하는 경우에는 사전에 소속부서의 장의 승인을 받아야 합니다. 다만, 불가피한 사유로 사전에 승인을 받을 수 없는 경우 결근 당일에라도 그 사유를 명확히 해 사후 승인을 받아야 하며, 정당한 이유 없이 이러한 절차를 이행하지 않은 경우 무단결근 처리 됩니다. \\n\n",
        "2-3. 지각 ․ 조퇴 및 외출 \\n\n",
        "① 사원은 질병 그 밖의 부득이한 사유로 지각하게 되는 경우에는 사전에 부서의 장 또는 직근 상급자에게 알려야 하며, 부득이한 사정으로 사전에 알릴 수 없는 경우에는 사후에 라도 지체없이 이 사실을 알려야 합니다. \\n\n",
        "② 사원은 근로시간 중에는 사적인 용무를 이유로 근무 장소를 이탈할 수 없습니다. 다만, 질병이나 그 밖의 부득이한 사유가 있는 경우에는 소속부서의 장의 승인을 받아 조퇴 또는 외출할 수 있습니다. \\n\n",
        "③ 사원이 지각, 조퇴 또는 외출한 시간은 무급으로 처리함을 원칙으로 합니다. \\n\n",
        "2-4. 공민권행사 및 공의 직무 수행 \\n\n",
        "① 회사는 사원이 근무시간 중 선거권, 그 밖의 공민권을 행사하거나 공(公)의 직무를 수행하기 위하여 필요한 시간을 청구할 경우 이를 거부할 수 없으며, 그 시간은 유급으로 처리합니다. \\n\n",
        "② 회사는 제1항의 권리 행사나 공(公)의 직무를 수행하는데 지장이 없는 범위 내에서 사원이 청구한 시간을 변경할 수 있습니다. \\n\n",
        "2-5. 출장 \\n\n",
        "①회사는 업무수행을 위해 필요한 경우 사원에게 출장을 명할 수 있습니다. \\n\n",
        "② 회사는 행선지별 여비, 숙박비, 현지교통비 등 출장 비용을 실비 범위 내에서 지급합니다. \\n\n",
        "\n",
        "Question:\n",
        "개인 사정으로 회사 결근\n",
        "\n",
        "Answer:\n",
        "① 사원은 업무시간 시작 전까지 출근해 업무에 임할 준비를 해 정상적인 업무수행에 차질이 없도록 해야 합니다. \\n\n",
        "② 질병이나 그 밖의 부득이한 사유로 결근하고자 하는 경우에는 사전에 소속부서의 장의 승인을 받아야 합니다. 다만, 불가피한 사유로 사전에 승인을 받을 수 없는 경우 결근 당일에라도 그 사유를 명확히 해 사후 승인을 받아야 하며, 정당한 이유 없이 이러한 절차를 이행하지 않은 경우 무 단결근 처리 됩니다. \\n\n",
        "\n",
        "Question:\n",
        "몸이 아파서 회사 못 가면 무단 결근 처리 돼?\n",
        "\n",
        "Answer:\n",
        "질병이나 그 밖의 부득이한 사유로 결근하고자 하는 경우에는 사전에 소속부서의 장의 승인을 받아야 합니다. 다만, 불가피한 사유로 사전에 승인을 받을 수 없는 경우 결근 당일에라도 그 사유를 명확히 해 사후 승인을 받아야 하며, 정당한 이유 없이 이러한 절차를 이행하지 않은 경우 무 단결근 처리 됩니다. \\n\n",
        "\n",
        "---\n",
        "\n",
        "Context:\n",
        "3. 인사 \\n\n",
        "3-1. 인사위원회 인사위원회 메뉴를 선택하셨네요. 아래 항목 중 궁금하신 내용을 선택해 주세요. \\n\n",
        "3-1-1. 인사위원회의 구성 \\n\n",
        "① 인사위원회는 대표이사와 부서장 또는 그에 준하는 직급의 사원 중 대표이사가 임명하는 자로 총 5명 이내로 구성하되 근로자위원을 최소 1명 이상 포함되도록 합니다. \\n\n",
        "② 위원회의 위원장은 대표이사 또는 대표이사가 위임한 자로 합니다. \\n\n",
        "③ 위원회에는 인사(총무)담당자 1명을 간사로 둡니다. \\n\n",
        "3-1-2. 위원회의 기능 위원회는 사원의 표창·징계에 관한 사항, 그 밖에 사원의 인사에 관해 위원회의 의결이 필요한 사항에 대해 의결합니다. \\n\n",
        "3-1-3. 위원회의 소집 및 운영 \\n\n",
        "① 위원회는 의결사항이 있을 경우 위원장이 소집하며, 원칙적으로 회의 개최 7일 전 회의일시, 장소, 의제 등을 각 위원에게 통보해야 해요. \\n\n",
        "② 위원회는 재적위원 과반수의 출석과 출석위원 과반수의 찬성으로 의결해요. 다만, 징계에 관한 사항은 재적위원 3분의 2 이상의 찬성으로 의결해야 해요. \\n\n",
        "③ 위원장은 표결권을 가지며 찬성하는 수와 반대하는 수가 동일할 때에는 결정권을 가져요. \\n\n",
        "④ 위원회의 회의는 공개하지 않으며 회의내용과 관련된 사항은 누설해서는 안되요. 다만, 위원회의 의결로 공개할 수 있어요. \\n\n",
        "⑤ 위원회의 의결사항이 특정위원에 관한 사항을 의결할 때에는 그 위원은 그 건의 의결에 참여할 수 없어요. \\n\n",
        "3-2. 배치・전직 및 승진 \\n\n",
        "① 회사는 사원의 능력, 적성, 경력 등을 고려하여 부서의 배치, 전직, 승진 등 인사발령을 하며, 사원은 정당한 사유 없이 이를 거부할 수 없습니다. \\n\n",
        "② 회사는 제1항에 따른 인사발령을 할 때 합리적인 이유 없이 남녀를 차별하지 않습니다. \\n\n",
        "③ 인사발령의 기준 등 필요한 사항에 대하여는 별도의 규정으로 정합니다. \\n\n",
        "3-3. 휴직 및 복직\\n\n",
        "3-3-1. 휴직사유 및 기간\\n\n",
        "휴직하려는 사원은 휴직을 시작하려는 날의 30일 전까지 회사에 휴직원을 제출해야 합니다.\\n\n",
        "다음과 같은 사유로 휴직할 수 있으며, 3번 조항을 제외하고는 무급을 원칙으로 합니다.\\n\n",
        "3-3-2. 휴직명령\\n\n",
        "① 회사는 사원이 휴직원을 제출하면 이를 심사하여 휴직명령 여부를 결정하여 사원에게 서면으로 통보합니다.\\n\n",
        "② 육아휴직의 경우, 사원이 휴직을 시작하려는 날의 전날까지 계속 근로한 기간이 6개월 미만일 때는 휴직명령을 하지 않을 수 있습니다.\\n\n",
        "3-3-3. 준수사항\\n\n",
        "① 휴직자는 휴직기간 중 거주지의 변동 등의 사유가 있을 때에는 지체 없이 회사에 그 사실을 알려야 합니다.\\n\n",
        "② 회사는 사원이 육아휴직하는 경우 고용보험법령이 정하는 육아휴직급여를 받을 수 있도록 증빙서류를 제공하는 등 적극 협조합니다.\\n\n",
        "3-3-4. 복직\\n\n",
        "① 사원은 휴직기간 만료일 7일 전까지 복직원을 제출해야 해요. 다만, 휴직기간의 연장이 필요한 경우 휴직기간 만료일 30일 전까지 그 사유를 명시하여 승인을 신청해야 합니다.\\n\n",
        "② 회사는 신청일부터 ㅇ일 내에 휴직사유별 기간의 범위 내에서 휴직기간의 연장 승인 여부를 결정하여 서면으로 통보합니다.\\n\n",
        "③ 사원은 휴직기간 중 휴직사유가 소멸되었을 때에는 지체없이 복직원을 제출해야 합니다.\\n\n",
        "④ 회사는 휴직 중인 사원으로부터 복직원을 제출 받은 경우에는 최대한 빠른 시일 내에 휴직 전의 직무에 복직시키도록 노력하되, 부득이한 경우에는 그와 유사한 업무나 동등한 수준의 급여가 지급되는 직무로 복귀시키도록 노력합니다.\\n\n",
        "3-3-5. 근속기간의 계산 등\\n\n",
        "① 휴직기간은 근속기간에 넣되, 평균임금* 산정기준이 되는 기간에서는 제외합니다.\\n\n",
        "② 병역법에 따라 휴직한 기간은 근로자퇴직급여 보장법에 따른 퇴직금 산정을 위한 계속근로기간에서 제외합니다.\\n\n",
        "*“평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을 그 기간의 총일수로 나눈 금액을 말해요. 근로자가 취업한 후 3개월 미만인 경우도 이에 준합니다.(근로기준법)\"\\n\n",
        "\n",
        "Question:\n",
        "6개월 미만으로 일한 사원도 휴직할 수 있나요?\n",
        "\n",
        "Answer:\n",
        "\n",
        "\"\"\"\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "    ).text\n",
        ")\n",
        "### 질문 예제\n",
        "# 승진\n",
        "# 인사위원회는 누가 임명해?\n",
        "# 인사위원회\n",
        "# 인사발령을 거부할 수 있어?\n",
        "# 회사에서 육아휴직 거부할 수 있나요\n",
        "# 6개월 미만으로 일한 사원도 휴직할 수 있나요"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WQmAPXyEP2d",
        "outputId": "866c90b3-9b02-4462-a220-ad1b6ba26f93"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "육아휴직의 경우, 사원이 휴직을 시작하려는 날의 전날까지 계속 근로한 기간이 6개월 미만일 때는 휴직명령을 하지 않을 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"징계\"\n",
        "prompt = f\"\"\"Answer the question given the context below as {{Context:}}. \\n\n",
        "If the answer is not available in the {{Context:}} and you are not confident about the output,\n",
        "please say \"Information not available in provided context\". \\n\\n\n",
        "Context: {context}?\\n\n",
        "Question: {question} \\n\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "print(\"[Prompt]\")\n",
        "print(prompt)\n",
        "\n",
        "print(\"[Response]\")\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "        max_output_tokens=256,\n",
        "        temperature=0.3,\n",
        "    ).text\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycfOnn9A50Ay",
        "outputId": "0c7dec27-4921-4b4c-f444-648289ff19a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prompt]\n",
            "Answer the question given the context below as {Context:}. \n",
            "\n",
            "If the answer is not available in the {Context:} and you are not confident about the output,\n",
            "please say \"Information not available in provided context\". \n",
            "\n",
            "\n",
            "Context: \n",
            "출장과 관련하여, 회사는 업무수행을 위해 필요한 경우 사원에게 출장을 명할 수 있습니다. 또한 회사는 행선지별 여비, 숙박비, 현지교통비 등 출장 비용을 실비 범위 내에서 지급합니다.\n",
            "\n",
            "비상시 임금 및 비용 지불과 관련하여, 사원이 다음 각 호의 사유로 청구하는 경우에는 지급기일 전이라도 이미 제공한 근로에 대한 임금을 지급합니다.\n",
            "\n",
            "1. 사원 또는 그의 수입에 의하여 생활을 유지하는 자의 출산, 질병 또는 재해의 비용에 충당하는 경우\n",
            "\n",
            "2. 사원 또는 그의 수입에 의하여 생활하는 자의 혼인 또는 사망 시 그 비용에 충당하는 경우\n",
            "\n",
            "3. 사원이 부득이한 사정으로 1주일 이상 귀향하는 경우\n",
            "\n",
            "?\n",
            "\n",
            "Question: 징계 \n",
            "\n",
            "Answer:\n",
            "\n",
            "[Response]\n",
            "Information not available in provided context\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 고객 예제 테스트 2. Turing 예제 (주로 규정집 기반 답변) - 규정집의 각 카테고리 별 내용을 Context 에 넣기 (each shot 마다 규정집 항목으로 context 정의)\n",
        "\n",
        "prompt = \"\"\"\n",
        "Context:\n",
        "주요 키워드 : 채용, 채용시 제출 서류 알려줘, 입사지원시 필요 서류, 채용심사 자료, 입사지원자가 제출해야 할 서류\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 입사지원자는 이력서 1통, 자기소개서 1통을 제출해야 합니다.\\n\n",
        "② 회사는 입사지원자에게 신체적 조건(용모‧키‧체중 등), 출신지역‧혼인여부‧재산, 직계존비속 및 형제자매의 학력‧직업‧재산 등 직무수행에 필요하지 않은 사항은 채용심사 등의 자료로 요구하지 않습니다.\\n\n",
        "\n",
        "Question:\n",
        "입사지원 서류\n",
        "\n",
        "Answer:\n",
        "입사지원자는 이력서 1통, 자기소개서 1통을 제출해야 합니다.\\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 근로계약, 근로계약 체결시 알려줘야 할 항목, 근로계약서 양식, 근로계약서 이메일로 보내줘도 돼?, 근로계약서 필수 포함항목\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 회사는 근로계약 체결시 다음 내용을 해당자에게 명확히 제시하고, 1~6번 내용이 포함된 근로계약서 1부를 근로계약을 체결한 사원에게 줍니다. \\n\n",
        "*해당 사원의 동의 하에 이를 전자적 방법(이메일 등)으로 보낼 수 있습니다.\\n\n",
        "1. 임금의 구성항목, 계산방법, 지급방법\\n\n",
        "2. 소정근로시간, 휴게시간\\n\n",
        "3. 휴일\\n\n",
        "4. 연차유급휴가\\n\n",
        "5. 취업의 장소 및 종사해야 할 업무에 관한 사항\\n\n",
        "6. 근로계약기간(기간제사원에 한정)\\n\n",
        "7. 근로기준법 제93조제1호부터 제12호까지에 해당하는 내용\\n\n",
        "8. 근로기준법 제10장에 따른 기숙사에 관한 사항(기숙사가 있는 경우에 한정)\\n\n",
        "② 회사는 근로계약 체결 시 제1항의 일부 내용을 대신하기 위한 것임을 명확히 밝히며 해당 내용이 적시된 취업규칙을 제시·교부할 수 있습니다.\\n\n",
        "\n",
        "Question:\n",
        "근로계약\n",
        "\n",
        "Answer:\n",
        "① 회사는 근로계약 체결시 다음 내용을 해당자에게 명확히 제시하고, 1~6번 내용이 포함된 근로계약서 1부를 근로계약을 체결한 사원에게 줍니다. \\n\n",
        "*해당 사원의 동의 하에 이를 전자적 방법(이메일 등)으로 보낼 수 있습니다.\\n\n",
        "1. 임금의 구성항목, 계산방법, 지급방법\\n\n",
        "2. 소정근로시간, 휴게시간\\n\n",
        "3. 휴일\\n\n",
        "4. 연차유급휴가\\n\n",
        "5. 취업의 장소 및 종사해야 할 업무에 관한 사항\\n\n",
        "6. 근로계약기간(기간제사원에 한정)\\n\n",
        "7. 근로기준법 제93조제1호부터 제12호까지에 해당하는 내용\\n\n",
        "8. 근로기준법 제10장에 따른 기숙사에 관한 사항(기숙사가 있는 경우에 한정)\\n\n",
        "② 회사는 근로계약 체결 시 제1항의 일부 내용을 대신하기 위한 것임을 명확히 밝히며 해당 내용이 적시된 취업규칙을 제시·교부할 수 있습니다.\\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 수습기간, 수습기간이 뭐야, 수습기간은 얼마나 돼, 수습기간도 평균임금산정기간에 포함 돼?, 수습기간도 근속년수에 포함 돼?, 수습기간 알려줘\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 신규채용자는 최초로 근무를 개시한 날부터 ㅇ개월간을 수습기간으로 합니다. \\n\n",
        "② 제1항의 수습기간은 근속년수에 포함하되, 수습시작일부터 3개월 이내의 기간은 평균임금산정기간에는 포함하지 않습니다.\\n\n",
        "\n",
        "Question:\n",
        "수습기간\n",
        "\n",
        "Answer:\n",
        "신규채용자는 최초로 근무를 개시한 날부터 ㅇ개월간을 수습기간으로 합니다. \\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 복무의무, 근무하면서 지켜야할 의무사항 있어, 근무하면서 꼭 지켜야 할 것, 근무시 태도, 회사에서 일할 때 태도, 공익신고자 보호, 업무상 기밀은 어떻게 해\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "1. 사원은 맡은바 직무를 충실히 수행해야 합니다. \\n\n",
        "2. 사원은 직무상 알게 된 비밀을 엄수하고 회사기밀을 누설해서는 안됩니다. 다만, 공익신고자 보호법상의 ‘공익신고자’의 경우에는 적용되지 않습니다.\\n\n",
        "3. 사원은 회사의 규정을 준수하고 상사의 정당한 직무상 지시에 따라야 합니다.\\n\n",
        "4. 사원은 사원으로서 품위를 손상하거나 회사의 명예를 실추시키는 행위를 해서는 안됩니다. \\n\n",
        "\n",
        "Question:\n",
        "근무하면서 지켜야 하는 사항\n",
        "\n",
        "Answer:\n",
        "1. 사원은 맡은바 직무를 충실히 수행해야 합니다. \\n\n",
        "2. 사원은 직무상 알게 된 비밀을 엄수하고 회사기밀을 누설해서는 안됩니다. 다만, 공익신고자 보호법상의 ‘공익신고자’의 경우에는 적용되지 않습니다.\\n\n",
        "3. 사원은 회사의 규정을 준수하고 상사의 정당한 직무상 지시에 따라야 합니다.\\n\n",
        "4. 사원은 사원으로서 품위를 손상하거나 회사의 명예를 실추시키는 행위를 해서는 안됩니다. \\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 출근, 결근, 미리 말 못하고 결근, 아파서 결근할 때, 무단결근 기준, 개인 사정으로 회사 결근, 몸이 아파서 회사 못 가면 무단 결근 처리 돼?\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 사원은 업무시간 시작 전까지 출근해 업무에 임할 준비를 해 정상적인 업무수행에 차질이 없도록 해야 합니다.\\n\n",
        "② 질병이나 그 밖의 부득이한 사유로 결근하고자 하는 경우에는 사전에 소속부서의 장의 승인을 받아야 합니다. \\n\n",
        "다만, 불가피한 사유로 사전에 승인을 받을 수 없는 경우 결근 당일에라도 그 사유를 명확히 해 사후 승인을 받아야 하며, 정당한 이유 없이 이러한 절차를 이행하지 않은 경우 무단결근 처리 됩니다.\\n\n",
        "\n",
        "Question:\n",
        "결근\n",
        "\n",
        "Answer:\n",
        "① 사원은 업무시간 시작 전까지 출근해 업무에 임할 준비를 해 정상적인 업무수행에 차질이 없도록 해야 합니다.\\n\n",
        "② 질병이나 그 밖의 부득이한 사유로 결근하고자 하는 경우에는 사전에 소속부서의 장의 승인을 받아야 합니다. \\n\n",
        "다만, 불가피한 사유로 사전에 승인을 받을 수 없는 경우 결근 당일에라도 그 사유를 명확히 해 사후 승인을 받아야 하며, 정당한 이유 없이 이러한 절차를 이행하지 않은 경우 무단결근 처리 됩니다.\\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 지각 ․ 조퇴 및 외출, 지각했을 때, 아파서 조퇴했는데 유급처리 되나요?, 지각, 조퇴, 외출한 시간은 임금에서 공제 되나요?, 외출한 시간은 무급이야?, 조퇴하면 무급으로 처리 되나요?\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 사원은 질병 그 밖의 부득이한 사유로 지각하게 되는 경우에는 사전에 부서의 장 또는 직근 상급자에게 알려야 하며, 부득이한 사정으로 사전에 알릴 수 없는 경우에는 사후에라도 지체없이 이 사실을 알려야 합니다.\\n\n",
        "② 사원은 근로시간 중에는 사적인 용무를 이유로 근무 장소를 이탈할 수 없습니다. 다만, 질병이나 그 밖의 부득이한 사유가 있는 경우에는 소속부서의 장의 승인을 받아 조퇴 또는 외출할 수 있습니다.\\n\n",
        "③ 사원이 지각, 조퇴 또는 외출한 시간은 무급으로 처리함을 원칙으로 합니다. \\n\n",
        "\n",
        "Question:\n",
        "조퇴 시 무급?\n",
        "\n",
        "Answer:\n",
        "사원이 지각, 조퇴 또는 외출한 시간은 무급으로 처리함을 원칙으로 합니다. \\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 공민권행사 및 공의 직무 수행, 선거일에 출근하면 중간에 선거하러 갈 수 있나요?, 선거 때문에 외출하면 유급 처리 되나요?, 예비군 때문에 결근하면 무급인가요?, 민방위 훈련시간은 유급이야?, 회사가 사원의 선거 시간을 지정할 수 있나요?        \\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 회사는 사원이 근무시간 중 선거권, 그 밖의 공민권을 행사하거나 공(公)의 직무를 수행하기 위하여 필요한 시간을 청구할 경우 이를 거부할 수 없으며, 그 시간은 유급으로 처리합니다.\\n\n",
        "② 회사는 제1항의 권리 행사나 공(公)의 직무를 수행하는데 지장이 없는 범위 내에서 사원이 청구한 시간을 변경할 수 있습니다.\\n\n",
        "\n",
        "Question:\n",
        "예비군\n",
        "\n",
        "Answer:\n",
        "① 회사는 사원이 근무시간 중 선거권, 그 밖의 공민권을 행사하거나 공(公)의 직무를 수행하기 위하여 필요한 시간을 청구할 경우 이를 거부할 수 없으며, 그 시간은 유급으로 처리합니다.\\n\n",
        "② 회사는 제1항의 권리 행사나 공(公)의 직무를 수행하는데 지장이 없는 범위 내에서 사원이 청구한 시간을 변경할 수 있습니다.\\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 출장, 출장에 대해 알려줘, 출장가면 숙박비 지원 해줘?, 출장비 받을 수 있어?, 출장비 지급 규정, 출장 갈 때 돈\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 회사는 업무수행을 위해 필요한 경우 사원에게 출장을 명할 수 있습니다.\\n\n",
        "② 회사는 행선지별 여비, 숙박비, 현지교통비 등 출장 비용을 실비 범위 내에서 지급합니다.\\n\n",
        "\n",
        "Question:\n",
        "출장비\n",
        "\n",
        "Answer:\n",
        "회사는 행선지별 여비, 숙박비, 현지교통비 등 출장 비용을 실비 범위 내에서 지급합니다.\\n\n",
        "\n",
        "---\n",
        "Context:\n",
        "주요 키워드 : 인사위원회의 구성, 인사위원회는 어떻게 구성되나요?, 인사위원회 구성 시 꼭 알아야 할 사항, 인사위원회는 누가 임명해?, 인사위원회는 누구 누구로 이뤄져?, 인사위원회에 꼭 넣어야 하는 사람\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 인사위원회는 대표이사와 부서장 또는 그에 준하는 직급의 사원 중 대표이사가 임명하는 자로 총 5명 이내로 구성하되 근로자위원을 최소 1명 이상 포함되도록 합니다.\\n\n",
        "② 위원회의 위원장은 대표이사 또는 대표이사가 위임한 자로 합니다. \\n\n",
        "③ 위원회에는 인사(총무)담당자 1명을 간사로 둡니다.\\n\n",
        "\n",
        "Question:\n",
        "인사위원회 임명\n",
        "\n",
        "Answer:\n",
        "① 인사위원회는 대표이사와 부서장 또는 그에 준하는 직급의 사원 중 대표이사가 임명하는 자로 총 5명 이내로 구성하되 근로자위원을 최소 1명 이상 포함되도록 합니다.\\n\n",
        "② 위원회의 위원장은 대표이사 또는 대표이사가 위임한 자로 합니다. \\n\n",
        "③ 위원회에는 인사(총무)담당자 1명을 간사로 둡니다.\\n\n",
        "---\n",
        "주요 키워드 : 배치・전직 및 승진, 인사발령, 인사발령 기준, 인사발령 관련 규정 알려줘, 승진 기준 알려줘, 인사발령 거부할 수 있나요\\n\n",
        "해당하는 답변 내용 :\\n\n",
        "① 회사는 사원의 능력, 적성, 경력 등을 고려하여 부서의 배치, 전직, 승진 등 인사발령을 하며, 사원은 정당한 사유 없이 이를 거부할 수 없습니다.\\n\n",
        "② 회사는 제1항에 따른 인사발령을 할 때 합리적인 이유 없이 남녀를 차별하지 않습니다.\\n\n",
        "③ 인사발령의 기준 등 필요한 사항에 대하여는 별도의 규정으로 정합니다.\\n\n",
        "\n",
        "\n",
        "Question:\n",
        "인사발령에 필요한 사항이 뭐야?\n",
        "\n",
        "Answer:\n",
        "\n",
        "\"\"\"\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "    ).text\n",
        ")\n",
        "\n",
        "## 질문 예제\n",
        "# 인사 발령 거부 가능할까?\n",
        "# 남녀 차별\n",
        "# 배치\n",
        "# 인사발령에 필요한 사항이 뭐야?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk1-h33y5nPP",
        "outputId": "835e7817-fdbe-405a-fba3-c9b344fe9f66"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "① 회사는 사원의 능력, 적성, 경력 등을 고려하여 부서의 배치, 전직, 승진 등 인사발령을 하며, 사원은 정당한 사유 없이 이를 거부할 수 없습니다.\n",
            "\n",
            "② 회사는 제1항에 따른 인사발령을 할 때 합리적인 이유 없이 남녀를 차별하지 않습니다.\n",
            "\n",
            "③ 인사발령의 기준 등 필요한 사항에 대하여는 별도의 규정으로 정합니다.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leYIui80Q4tH"
      },
      "source": [
        "### Extractive Question-Answering\n",
        "\n",
        "In the next example, the generative model is guided to understand the meaning of the question and the passage, and to identify the relevant information in the passage that answers the question. The model is given a question and a passage of text, and is asked to find the answer to the question within the passage. The answer is typically a phrase or sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bPZqm0QJQ4tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316e873c-8be1-4786-9953-ba5791716f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced moist tropical vegetation cover in the basin.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Background: There is evidence that there have been significant changes in Amazon rainforest vegetation over the last 21,000 years through the Last Glacial Maximum (LGM) and subsequent deglaciation.\n",
        "Analyses of sediment deposits from Amazon basin paleo lakes and from the Amazon Fan indicate that rainfall in the basin during the LGM was lower than for the present, and this was almost certainly\n",
        "associated with reduced moist tropical vegetation cover in the basin. There is debate, however, over how extensive this reduction was. Some scientists argue that the rainforest was reduced to small,\n",
        "isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today.\n",
        "This debate has proved difficult to resolve because the practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin, and both\n",
        "explanations are reasonably well supported by the available data.\n",
        "\n",
        "Q: What does LGM stands for?\n",
        "A: Last Glacial Maximum.\n",
        "\n",
        "Q: What did the analysis from the sediment deposits indicate?\n",
        "A: Rainfall in the basin during the LGM was lower than for the present.\n",
        "\n",
        "Q: What are some of scientists arguments?\n",
        "A: The rainforest was reduced to small, isolated refugia separated by open forest and grassland.\n",
        "\n",
        "Q: There have been major changes in Amazon rainforest vegetation over the last how many years?\n",
        "A: 21,000.\n",
        "\n",
        "Q: What caused changes in the Amazon rainforest vegetation?\n",
        "A: The Last Glacial Maximum (LGM) and subsequent deglaciation\n",
        "\n",
        "Q: What has been analyzed to compare Amazon rainfall in the past and present?\n",
        "A: Sediment deposits.\n",
        "\n",
        "Q: What has the lower rainfall in the Amazon during the LGM been attributed to?\n",
        "A:\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt,\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94d80fb55f48"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b620d23a7634"
      },
      "source": [
        "You can evaluate the outputs of the question and answering task if the ground truth answers of each question are available. In zero-shot prompting, you can only use `open domain` questions. However, with `closed domain` questions, you can add context and evaluate similarly.  To showcase how that will work, start by creating a simple dataframe with questions and ground truth answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8e813a463531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "d4ae3259-91cb-4327-b5e7-7979c50b10ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question answer_groundtruth\n",
              "0  In a website browser address bar, what does “w...     World Wide Web\n",
              "1       Who was the first woman to win a Nobel Prize        Marie Curie\n",
              "2     What is the name of the Earth’s largest ocean?  The Pacific Ocean"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-8e4a6ce6-fc43-44fb-8cac-231d82ae39d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_groundtruth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In a website browser address bar, what does “w...</td>\n",
              "      <td>World Wide Web</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who was the first woman to win a Nobel Prize</td>\n",
              "      <td>Marie Curie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the name of the Earth’s largest ocean?</td>\n",
              "      <td>The Pacific Ocean</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e4a6ce6-fc43-44fb-8cac-231d82ae39d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-49ae6510-5428-47db-bb6a-a4818d823a9b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49ae6510-5428-47db-bb6a-a4818d823a9b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-49ae6510-5428-47db-bb6a-a4818d823a9b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e4a6ce6-fc43-44fb-8cac-231d82ae39d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e4a6ce6-fc43-44fb-8cac-231d82ae39d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "qa_data = {\n",
        "    \"question\": [\n",
        "        \"In a website browser address bar, what does “www” stand for?\",\n",
        "        \"Who was the first woman to win a Nobel Prize\",\n",
        "        \"What is the name of the Earth’s largest ocean?\",\n",
        "    ],\n",
        "    \"answer_groundtruth\": [\"World Wide Web\", \"Marie Curie\", \"The Pacific Ocean\"],\n",
        "}\n",
        "qa_data_df = pd.DataFrame(qa_data)\n",
        "qa_data_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data = {\n",
        "    \"question\": [\n",
        "        \"산업재해\",\n",
        "        \"출장\",\n",
        "        \"교통\",\n",
        "    ]\n",
        "}\n",
        "qa_data_df = pd.DataFrame(qa_data)\n",
        "qa_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "4ONXU01MNJVY",
        "outputId": "30d6e445-7734-43fd-db94-76641aa41b44"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  question\n",
              "0     산업재해\n",
              "1       출장\n",
              "2       교통"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f8c7f557-f094-4d13-a215-af3a8a5bb6b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>산업재해</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>출장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>교통</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8c7f557-f094-4d13-a215-af3a8a5bb6b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-72cf7f68-873d-4726-b04b-d3e648775113\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72cf7f68-873d-4726-b04b-d3e648775113')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-72cf7f68-873d-4726-b04b-d3e648775113 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8c7f557-f094-4d13-a215-af3a8a5bb6b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8c7f557-f094-4d13-a215-af3a8a5bb6b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "951a147dc79d"
      },
      "source": [
        "Now that you have the data with questions and ground truth answers, you can call the PaLM 2 generation model to each review row using the `apply` function. Each row will use the dynamic prompt to predict the answer using the PaLM API. We will save the results in `answer_prediction` column.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ffc47e0cb5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "bfc76469-7321-4471-c12a-74206fa296dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  question                                 answer_prediction\n",
              "0     산업재해  산업재해(industrial accident)는 산업 활동 중 발생하는 사고를 말한다.\n",
              "1       출장                                       출장 (Korean)\n",
              "2       교통                             교통은 움직이는 물체의 흐름을 말한다."
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-690cb32e-c518-4968-af6a-2e5d4adfb97a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>산업재해</td>\n",
              "      <td>산업재해(industrial accident)는 산업 활동 중 발생하는 사고를 말한다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>출장</td>\n",
              "      <td>출장 (Korean)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>교통</td>\n",
              "      <td>교통은 움직이는 물체의 흐름을 말한다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-690cb32e-c518-4968-af6a-2e5d4adfb97a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-95b2c171-8795-485d-b9b4-033200ae73dd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95b2c171-8795-485d-b9b4-033200ae73dd')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-95b2c171-8795-485d-b9b4-033200ae73dd button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-690cb32e-c518-4968-af6a-2e5d4adfb97a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-690cb32e-c518-4968-af6a-2e5d4adfb97a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "def get_answer(row):\n",
        "    prompt = f\"\"\"Answer the following question as precise as possible.\\n\\n\n",
        "            question: {row}\n",
        "            answer:\n",
        "              \"\"\"\n",
        "    return generation_model.predict(\n",
        "        prompt=prompt,\n",
        "    ).text\n",
        "\n",
        "\n",
        "qa_data_df[\"answer_prediction\"] = qa_data_df[\"question\"].apply(get_answer)\n",
        "qa_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fe997dbf788"
      },
      "source": [
        "You may want to evaluate the answers predicted by the PaLM API. However, it will be more complex than the text classification since the answers may differ from ground truth and may be presented in slightly more/fewer words.\n",
        "\n",
        "For example, you can observe the question \"What is the name of the Earth's largest ocean?\" and see that model predicted  \"Pacific Ocean\" when a ground truth label is \"The Pacific Ocean\" with the extra \"The.\" Now, if you use the simple classification metrics, then you will consider this as a wrong prediction since original and predicted strings have a difference. However, you can see that the answer is correct since an extra \"The\" is causing the issue. It's a simple string comparison problem.\n",
        "\n",
        "The solution to string comparison where both `ground_thruth` and `predicted` may have some extra or fewer letters, one approach is to use a fuzzy matching algorithm.\n",
        "Fuzzy string matching uses [Levenshtein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance) to calculate the differences between two strings.\n",
        "\n",
        "For example, the Levenshtein distance between \"kitten\" and \"sitting\" is 3, since the following 3 edits change one into the other, and there is no way to do it with fewer than 3 edits:\n",
        "\n",
        "* kitten → sitten (substitution of \"s\" for \"k\"),\n",
        "* sitten → sittin (substitution of \"i\" for \"e\"),\n",
        "* sittin → sitting (insertion of \"g\" at the end).\n",
        "\n",
        "\n",
        "Here's another example, but this time using `fuzzywuzzy`  library, which gives us the same `Levenshtein distance` between two strings but in ratio. The ratio raw score measures the string's similarity as an int in the range [0, 100]. For two strings X and Y, the score is defined by int(round((2.0 * M / T) * 100)) where T is the total number of characters in both strings, and M is the number of matches in the two strings.\n",
        "\n",
        "Read more here about the [ratio formula](https://anhaidgroup.github.io/py_stringmatching/v0.3.x/Ratio.html) :\n",
        "\n",
        "You can see one example to understand this furhter.\n",
        "```\n",
        "String1: \"this is a test\"\n",
        "String2: \"this is a test!\"\n",
        "\n",
        "Fuzz Ratio => 97  #\n",
        "\n",
        "Fuzz Partial Ratio => 100  #Since most characters are the same and in a similar sequence, the algorithm calculates the partial ratio as 100 and ignores simple additions (new characters).\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b170579a455"
      },
      "source": [
        "First, install the package `fuzzywuzzy` and `python-Levenshtein`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6c55ea0eaed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253336e8-3c2a-4124-b4bc-c0dc1da10293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q python-Levenshtein --upgrade --user\n",
        "!pip install -q fuzzywuzzy --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f048152519f"
      },
      "source": [
        "Then compute a score to perform fuzzy matching:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "040c1f9a175b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "51ddc555-2b15-4a07-b542-e70867d76f2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question answer_groundtruth  \\\n",
              "0  In a website browser address bar, what does “w...     World Wide Web   \n",
              "1       Who was the first woman to win a Nobel Prize        Marie Curie   \n",
              "2     What is the name of the Earth’s largest ocean?  The Pacific Ocean   \n",
              "\n",
              "  answer_prediction  match_score  \n",
              "0    World Wide Web          100  \n",
              "1       Marie Curie          100  \n",
              "2     Pacific Ocean          100  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-095fbb06-8bb1-4103-b5d9-73315592b8ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_groundtruth</th>\n",
              "      <th>answer_prediction</th>\n",
              "      <th>match_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In a website browser address bar, what does “w...</td>\n",
              "      <td>World Wide Web</td>\n",
              "      <td>World Wide Web</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who was the first woman to win a Nobel Prize</td>\n",
              "      <td>Marie Curie</td>\n",
              "      <td>Marie Curie</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the name of the Earth’s largest ocean?</td>\n",
              "      <td>The Pacific Ocean</td>\n",
              "      <td>Pacific Ocean</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-095fbb06-8bb1-4103-b5d9-73315592b8ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f8b98663-5f84-4280-b0e3-6567d3d24aac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8b98663-5f84-4280-b0e3-6567d3d24aac')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f8b98663-5f84-4280-b0e3-6567d3d24aac button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-095fbb06-8bb1-4103-b5d9-73315592b8ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-095fbb06-8bb1-4103-b5d9-73315592b8ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "\n",
        "def get_fuzzy_match(df):\n",
        "    return fuzz.partial_ratio(df[\"answer_groundtruth\"], df[\"answer_prediction\"])\n",
        "\n",
        "\n",
        "qa_data_df[\"match_score\"] = qa_data_df.apply(get_fuzzy_match, axis=1)\n",
        "qa_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11e266c49860"
      },
      "source": [
        "Now that you have the individual match score (partial), you can take the mean or average of the whole column to get a sense of overall data.\n",
        "Scores closer to 100 mean PaLM 2 can predict closer to ground truth; if the score is towards 50 or 0, it did not perform well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dae6a92a7650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf35fc5e-ed47-4e38-cf65-dd0d68b41569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the average match score of all predicted answer from PaLM 2 is :  100.0  %\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"the average match score of all predicted answer from PaLM 2 is : \",\n",
        "    qa_data_df[\"match_score\"].mean(),\n",
        "    \" %\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9e78972cad1"
      },
      "source": [
        "In this case, you get 100% as the mean score, even though some predictions were missing some words. That means you are very close to the ground truth, and some answers are just missing the exact verboseness of the ground truth."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "question_answering.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}